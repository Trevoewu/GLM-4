import streamlit as st
import sys
import os
import logging
from pathlib import Path
import time # Added for streamlit_chat_app.py

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from rag_system import RAGSystem
import config

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="RAGæ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

@st.cache_resource
def initialize_rag_system():
    """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
    try:
        rag_system = RAGSystem()
        # é¢„åŠ è½½å‘é‡å­˜å‚¨
        rag_system.load_vector_store()
        return rag_system
    except Exception as e:
        st.error(f"åˆå§‹åŒ–RAGç³»ç»Ÿå¤±è´¥: {str(e)}")
        return None

def display_sources_with_streamlit(sources):
    """ä½¿ç”¨Streamlitå†…ç½®ç»„ä»¶æ˜¾ç¤ºæ–‡æ¡£æ¥æº"""
    if sources:
        st.markdown("**ğŸ“š ç›¸å…³æ–‡æ¡£æ¥æº:**")
        
        for i, source in enumerate(sources, 1):
            with st.expander(f"ğŸ“„ ç›¸å…³æ–‡æ¡£ {i}: {source.get('title', 'æœªçŸ¥æ–‡æ¡£')}", expanded=False):
                st.markdown(f"**æ–‡æ¡£å†…å®¹:**")
                st.text(source.get('content', ''))
                if source.get('metadata'):
                    st.markdown(f"**å…ƒæ•°æ®:**")
                    st.json(source.get('metadata', {}))

def display_retrieval_process(rag_system, prompt, top_k):
    """æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹"""
    st.markdown("**ğŸ” æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...**")
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # æ¨¡æ‹Ÿæ£€ç´¢æ­¥éª¤
    steps = [
        "æ­£åœ¨åˆ†æé—®é¢˜...",
        "æ­£åœ¨è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦...",
        "æ­£åœ¨æ£€ç´¢å‘é‡æ•°æ®åº“...",
        "æ­£åœ¨æ’åºç›¸å…³æ–‡æ¡£...",
        "æ£€ç´¢å®Œæˆï¼"
    ]
    
    for i, step in enumerate(steps):
        status_text.text(step)
        progress_bar.progress((i + 1) / len(steps))
        time.sleep(0.5)
    
    # æ‰§è¡Œå®é™…æ£€ç´¢
    relevant_docs = rag_system.vector_store.similarity_search(prompt, k=top_k)
    
    # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
    st.success(f"âœ… æ‰¾åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£")
    
    # æ˜¾ç¤ºæ£€ç´¢åˆ°çš„æ–‡æ¡£é¢„è§ˆ
    with st.expander("ğŸ“‹ æ£€ç´¢åˆ°çš„æ–‡æ¡£é¢„è§ˆ", expanded=False):
        for i, doc in enumerate(relevant_docs, 1):
            st.markdown(f"**æ–‡æ¡£ {i}:**")
            st.text(doc.page_content[:200] + "...")
            if doc.metadata:
                st.markdown(f"*æ¥æº: {doc.metadata.get('source_file', 'æœªçŸ¥')}*")
            st.divider()
    
    return relevant_docs

def main():
    # ä¸»æ ‡é¢˜
    st.title("ğŸ¤– RAGæ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    st.markdown("åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆçš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œä¸ºæ‚¨æä¾›å‡†ç¡®ã€å¯é çš„ç­”æ¡ˆ")
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        
        rag_system = initialize_rag_system()
        
        if rag_system:
            # å‚æ•°è®¾ç½®
            st.subheader("ğŸ”§ å‚æ•°è®¾ç½®")
            top_k = st.slider("æ£€ç´¢æ–‡æ¡£æ•°é‡", min_value=1, max_value=10, value=3, help="ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢çš„ç›¸å…³æ–‡æ¡£æ•°é‡")
            temperature = st.slider("ç”Ÿæˆæ¸©åº¦", min_value=0.0, max_value=1.0, value=0.7, step=0.1, help="æ§åˆ¶ç­”æ¡ˆç”Ÿæˆçš„åˆ›é€ æ€§")
            
            # æµå¼è¾“å‡ºè®¾ç½®
            st.subheader("ğŸ”„ è¾“å‡ºè®¾ç½®")
            use_streaming = st.checkbox("å¯ç”¨æµå¼è¾“å‡º", value=True, help="å®æ—¶æ˜¾ç¤ºç”Ÿæˆè¿‡ç¨‹")
            
            # æ£€ç´¢è¿‡ç¨‹æ˜¾ç¤ºè®¾ç½®
            st.subheader("ğŸ” æ£€ç´¢è®¾ç½®")
            show_retrieval = st.checkbox("æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹", value=True, help="æ˜¾ç¤ºæ–‡æ¡£æ£€ç´¢çš„è¯¦ç»†è¿‡ç¨‹")
            
        else:
            st.error("âŒ RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            st.stop()
    
    # ä¸»èŠå¤©ç•Œé¢
    # åˆå§‹åŒ–èŠå¤©å†å²
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message.get("sources"):
                display_sources_with_streamlit(message["sources"])
    
    # èŠå¤©è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” æ­£åœ¨æ€è€ƒä¸­..."):
                try:
                    # æ˜¾ç¤ºæ£€ç´¢è¿‡ç¨‹
                    if show_retrieval:
                        relevant_docs = display_retrieval_process(rag_system, prompt, top_k)
                    else:
                        # é™é»˜æ£€ç´¢
                        relevant_docs = rag_system.vector_store.similarity_search(prompt, k=top_k)
                    
                    # è·å–ç­”æ¡ˆ
                    if use_streaming:
                        # æµå¼è¾“å‡º
                        message_placeholder = st.empty()
                        full_response = ""
                        
                        # æ„å»ºæç¤º
                        context = "\n".join([doc.page_content for doc in relevant_docs])
                        
                        # è½¬æ¢æ–‡æ¡£æ ¼å¼ï¼ˆä¸æ™®é€šè¾“å‡ºä¿æŒä¸€è‡´ï¼‰
                        relevant_docs_formatted = [
                            {
                                "content": rag_system._clean_text(doc.page_content[:300]) + "...",
                                "metadata": doc.metadata
                            }
                            for doc in relevant_docs
                        ]
                        prompt_text = f"""åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè¯·å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜æ— æ³•ä»æä¾›çš„æ–‡æ¡£ä¸­æ‰¾åˆ°ç­”æ¡ˆã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

é—®é¢˜ï¼š{prompt}

è¯·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ï¼š"""
                        
                        # æ¨¡æ‹Ÿæµå¼è¾“å‡º
                        try:
                            # è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸæ­£çš„æµå¼LLMï¼Œç°åœ¨å…ˆæ¨¡æ‹Ÿ
                            answer = rag_system.llm._call(prompt_text)
                            
                            # æ¨¡æ‹Ÿé€å­—æ˜¾ç¤ºï¼ˆä¿æŒMarkdownæ ¼å¼ï¼‰
                            # å°†ç­”æ¡ˆæŒ‰å¥å­åˆ†å‰²ï¼Œä¿æŒMarkdownæ ¼å¼
                            sentences = answer.split('ã€‚')
                            full_response = ""
                            
                            for i, sentence in enumerate(sentences):
                                if sentence.strip():
                                    full_response += sentence + "ã€‚"
                                    message_placeholder.markdown(full_response + "â–Œ")
                                    time.sleep(0.2)
                            
                            # æœ€ç»ˆæ˜¾ç¤ºå®Œæ•´çš„Markdownæ ¼å¼ç­”æ¡ˆ
                            message_placeholder.markdown(answer)
                            
                        except Exception as e:
                            # å¦‚æœæµå¼è¾“å‡ºå¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šè¾“å‡º
                            response = rag_system.answer_question(prompt)
                            answer = response.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚")
                            relevant_docs = response.get("relevant_documents", [])
                            st.markdown(answer)
                    else:
                        # æ™®é€šè¾“å‡º
                        response = rag_system.answer_question(prompt)
                        answer = response.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°ç›¸å…³ç­”æ¡ˆã€‚")
                        relevant_docs = response.get("relevant_documents", [])
                        st.markdown(answer)
                    
                    # è½¬æ¢æ–‡æ¡£æ ¼å¼
                    sources = []
                    if use_streaming:
                        # æµå¼è¾“å‡ºä½¿ç”¨å·²æ ¼å¼åŒ–çš„æ–‡æ¡£
                        for i, doc in enumerate(relevant_docs_formatted, 1):
                            sources.append({
                                "title": f"ç›¸å…³æ–‡æ¡£ {i}",
                                "content": doc.get("content", ""),
                                "metadata": doc.get("metadata", {})
                            })
                    else:
                        # æ™®é€šè¾“å‡ºä½¿ç”¨responseä¸­çš„æ–‡æ¡£
                        for i, doc in enumerate(relevant_docs, 1):
                            sources.append({
                                "title": f"ç›¸å…³æ–‡æ¡£ {i}",
                                "content": doc.get("content", ""),
                                "metadata": doc.get("metadata", {})
                            })
                    
                    # æ˜¾ç¤ºæ¥æº
                    display_sources_with_streamlit(sources)
                    
                    # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": answer,
                        "sources": sources
                    })
                    
                except Exception as e:
                    error_msg = f"å¤„ç†é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
                    st.error(error_msg)
                    logger.error(f"æŸ¥è¯¢é”™è¯¯: {str(e)}")
    
    # åº•éƒ¨æ§åˆ¶æŒ‰é’®
    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", use_container_width=True):
            st.session_state.messages = []
            st.rerun()

if __name__ == "__main__":
    main() 